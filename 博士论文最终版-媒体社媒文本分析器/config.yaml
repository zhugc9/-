# ==============================================================================
# 媒体文本与社交媒体分析系统 - 统一配置文件
# ==============================================================================

# ==============================================================================
# 📁 文件路径配置
# ==============================================================================
file_paths:
  # 媒体文本分析：输入文件夹路径
  input: "C:\\Users\\87010\\Desktop\\媒体文本议题单元划分素材"
  
  # 媒体文本分析：输出文件夹路径
  output: "C:\\Users\\87010\\Desktop\\媒体文本议题单元划分结果"

# 社交媒体分析路径配置（兼容旧版本配置格式）
INPUT_PATH: "C:\\Users\\87010\\Desktop\\社交媒体议题单元划分素材"
OUTPUT_PATH: "C:\\Users\\87010\\Desktop\\社交媒体议题单元划分结果"

# ==============================================================================
# 🔄 自动重试配置（媒体文本专用）
# ==============================================================================
auto_retry:
  enabled: true  # 是否启用自动重试功能
  max_retry_rounds: 5  # 最大重试轮数（防止无限循环）
  retry_delay_minutes: 2  # 重试前等待时间（分钟）
  min_failed_threshold: 1  # 触发重试的最小失败记录数

# ==============================================================================
# 🔬 信度检验配置 - 统一三阶段验证方案
# ==============================================================================
reliability_test:
  enabled: true  # 是否生成信度检验文件

  sampling_config:
    # 媒体文本信源抽样配置
    俄总统:
      precision: 80    # 主样本库：成功议题单元抽样数（用于准确率+单元构建+多维编码检验）
      recall: 40       # 召回率检验：被舍弃完整文章抽样数
    俄语媒体:
      precision: 80    
      recall: 40       
    中文媒体:
      precision: 80
      recall: 40
    英语媒体:
      precision: 80
      recall: 40
    未知来源:
      precision: 80
      recall: 40
    
    # 社交媒体信源抽样配置
    vk:  # VK平台：50个召回率样本
      recall: 50
    知乎:  # 知乎平台
      recall: 50

# 兼容旧版本配置格式
RELIABILITY_TEST_MODE: true
RELIABILITY_SAMPLING_CONFIG:
  vk:
    recall: 50

# ==============================================================================
# 🔄 API重试策略配置
# ==============================================================================
api_retry_config:
  attempts_per_model: 3        # 每个模型连续尝试3次
  max_model_switches: 2        # 最多切换2次：主模型3次→备用模型3次→放弃(共6次尝试)
  retry_delays: [2, 5, 10]     # 重试延迟（秒）
  max_concurrent_requests: 2   # 最大并发请求数
  queue_timeout: 30.0          # 队列等待超时（秒）

# ==============================================================================
# 💾 缓冲区配置
# ==============================================================================
buffer_config:
  # 分析结果缓冲区大小（条数）
  analysis_buffer_limit: 20

# ==============================================================================
# 🤖 API请求参数配置
# ==============================================================================
api_request_params:
  # 温度参数：控制输出的随机性，0=确定性输出
  temperature: 0
  # 响应格式：强制JSON格式输出
  response_format:
    type: "json_object"

# ==============================================================================
# 📊 文本处理配置
# ==============================================================================
# 文本长度限制（防止超出模型上下文限制）
LANGUAGE_CONFIGS:
  zh:
    MAX_SINGLE_TEXT: 50000    # 中文单篇文章最大token数
    TIMEOUT: 600              # API超时时间（秒）
    MAX_CONCURRENT: 2         # 最大并发数
  en:
    MAX_SINGLE_TEXT: 50000    # 英文单篇文章最大token数
    BATCH_SIZE_LIMIT: 30      # 批处理大小限制
    TIMEOUT: 240              # API超时时间（秒）
    MAX_CONCURRENT: 6         # 最大并发数
    SAVE_INTERVAL: 10         # 保存间隔
  ru:
    MAX_SINGLE_TEXT: 50000    # 俄文单篇文章最大token数
    BATCH_SIZE_LIMIT: 100     # 批处理大小限制
    TIMEOUT: 180              # API超时时间（秒）
    MAX_CONCURRENT: 2         # 最大并发数
    SAVE_INTERVAL: 20         # 保存间隔

# API超时配置（根据文本长度自动调整）
TIMEOUT_CONFIG:
  TOKEN_THRESHOLD_SHORT: 2000    # 短文本：≤2000 tokens
  TOKEN_THRESHOLD_MEDIUM: 4000   # 中等文本：2001-4000 tokens
  
  TIMEOUT_SHORT: 400             # 短文本超时：400秒
  TIMEOUT_MEDIUM: 500            # 中等文本超时：500秒  
  TIMEOUT_LONG: 500              # 长文本超时：500秒（>4000 tokens）

# 数据处理配置
data_processing:
  skip_failed_texts: true       # 遇到失败文本时继续处理其他文本
  
  # 数据质量验证阈值
  quality_thresholds:
    text_similarity_threshold: 0.7    # 文本相似度匹配阈值
    token_char_ratio: 2               # Token与字符数的粗略比例（备用计算）

# 社交媒体特有配置（兼容旧版本）
MAX_CONCURRENT_REQUESTS: 2    # 最大并发请求数（避免API限流）
API_RETRY_ATTEMPTS: 3         # API失败重试次数
RATE_LIMIT_BASE_DELAY: 2      # 基础延迟时间（秒），重试时会指数增长
SKIP_FAILED_TEXTS: true       # 是否跳过API失败的文本（True=跳过，False=抛出异常）

# 文本长度智能模型选择配置
VK_LONG_TEXT_THRESHOLD: 1500      # VK批处理长文本阈值（token数）
ZHIHU_SHORT_TOKEN_THRESHOLD: 100  # 知乎短文本阈值
ZHIHU_LONG_TOKEN_THRESHOLD: 1300  # 知乎长文本阈值

# ==============================================================================
# 🎲 随机化配置
# ==============================================================================
randomization:
  # 随机种子：用于确保结果可重现
  random_seed: 2025

# ==============================================================================
# 🔑 API配置
# ==============================================================================
api_config:
  # API密钥列表：支持多个密钥轮换
  API_KEYS:
    - "sk-o
  
  # API基础URL：代理服务地址
  BASE_URL: "https://openai.sharkmagic.com.cn/v1"

# 兼容旧版本配置格式
API_CONFIG:
  API_KEYS:
    - "sk-oS1mPzoH"
  BASE_URL: "https://openai.sharkmagic.com.cn/v1"
  
  # 不同处理阶段的模型配置
  STAGE_MODELS:
    # 媒体文本两阶段模型
    UNIT_EXTRACTION: "[官自-3]gemini-2-5-pro"               # 第一阶段：议题单元提取
    UNIT_ANALYSIS: "[官自-0.7]gemini-2-5-flash"             # 第二阶段：单元深度分析
    
    # 社交媒体处理模型
    VK_BATCH: "[官自-0.7]gemini-2-5-flash"                  # VK批处理：使用较高质量模型
    VK_BATCH_LONG: "[官自-3]gemini-2-5-pro"                 # VK长文本批处理：使用高性能模型
    ZHIHU_CHUNKING: "[官自-0.7]gemini-2-5-flash"            # 知乎分块：使用较高质量模型
    ZHIHU_ANALYSIS: "[官自-0.7]gemini-2-5-flash"            # 知乎分析：使用较高质量模型
    ZHIHU_ANALYSIS_SHORT: "[官自-0.3]gemini-2-5-flash-lite" # 知乎短文本分析：使用轻量快速模型
    ZHIHU_ANALYSIS_LONG: "[官自-3]gemini-2-5-pro"           # 知乎长文本分析：使用高性能模型

# ==============================================================================
# 🤖 模型池配置（媒体文本专用）
# ==============================================================================
model_pools:
  # 主模型配置：两阶段处理模型
  primary_models:
    UNIT_EXTRACTION: "[官自-3]gemini-2-5-pro"               # 第一阶段：议题单元提取，长文本强模型
    UNIT_ANALYSIS: "[官自-0.7]gemini-2-5-flash"             # 第二阶段：单元深度分析，高性价比快速模型
  
  # 备用模型池：主模型失败时的降级选择
  fallback_models:
    UNIT_EXTRACTION:
      - "[羊毛-2]gemini-2.5-pro-0605-100k"                            
    UNIT_ANALYSIS:
      - ""

# ==============================================================================
# 📋 Excel列名映射
# ==============================================================================
# 将Excel文件中的列名映射为程序内部使用的标准名称
column_mapping:
  # 媒体文本列名映射
  ID: "序号"           # 文章ID列名：Excel中用于标识每篇文章的唯一编号
  MEDIA_TITLE: "标题"  # 文章标题列名：Excel中存储文章标题的列名
  MEDIA_TEXT: "text"   # 文章正文列名：Excel中存储文章正文内容的列名

# 社交媒体列名映射（兼容旧版本）
COLUMN_MAPPING:
  vk:  # VK平台数据列名映射
    post_id: "post_id"           # 帖子ID列
    post_text: "post_text"       # 帖子内容列
    comment_id: "comment_id"     # 评论ID列
    comment_text: "comment_text" # 评论内容列
    channel_name: "channel_name" # 频道名称列
  zhihu:  # 知乎平台数据列名映射
    id: "序号"                    # 回答序号列
    question: "知乎问题标题及描述"  # 问题内容列
    answer_text: "回答内容"       # 回答内容列
    author: "回答用户名"           # 回答作者列

# ==============================================================================
# 📊 统一输出列
# ==============================================================================
# 用于强制补齐，避免不同语言/批次导致列缺失
# 该列表定义了所有输出Excel文件必须包含的列名
required_output_columns:
  # 输入基础列（保持在最前）
  - "序号"      # 文章唯一标识
  - "日期"      # 文章发布日期
  - "标题"      # 文章标题
  - "token数"   # 文章token数统计
  - "text"      # 文章正文内容
  
  # 议题单元输出列
  - "Unit_ID"                    # 议题单元唯一标识
  - "Source"                     # 信源标识（俄总统/俄语媒体/中文媒体/英语媒体/未知来源）
  - "speaker"                    # 发言人/信源标准化标识
  - "Unit_Text"                  # 议题单元原文
  - "seed_sentence"              # 种子句子（用于单元构建的锚点）
  - "expansion_logic"            # 单元构建逻辑报告
  - "Unit_Hash"                  # 单元文本哈希值（用于去重）
  - "processing_status"          # 处理状态（SUCCESS/NO_RELEVANT/API_FAILED）
  
  # 核心事件提取
  - "Incident"                   # 核心事件、观点或行动的一句话概括
  
  # 六维框架功能分析（对象格式）- 按优先级排序
  - "Frame_SolutionRecommendation"   # 方案建议（优先级1，对象列表：quote, reason, reasoning_pattern）
  - "Frame_ResponsibilityAttribution" # 归因指责（优先级2，对象列表：quote, reason, reasoning_pattern）
  - "Frame_CausalExplanation"        # 因果解释（优先级3，对象列表：quote, reason, reasoning_pattern）
  - "Frame_MoralEvaluation"          # 道德评价（优先级4，对象列表：quote, reason, reasoning_pattern）
  - "Frame_ProblemDefinition"        # 问题建构（优先级5，对象列表：quote, reason, reasoning_pattern）
  - "Frame_ActionStatement"          # 事实宣称（优先级6，对象列表：quote, reason, reasoning_pattern）
  
  # 核心分析维度
  - "Valence"                           # 情感极性（正面/负面/中立/事实陈述）
  - "Evidence_Type"                     # 证据类型（数据/统计/官方声明/专家观点等）
  - "Attribution_Level"                 # 归因层级（个体/国家/社会/系统/不适用）
  - "Temporal_Focus"                    # 时间焦点（追溯/现状/展望/混合）
  - "Primary_Actor_Type"                # 主要行动者类型（国家/个人/次国家/国际组织等）
  - "Geographic_Scope"                  # 地理范围（双边/区域/全球/国内/混合）
  - "Relationship_Model_Definition"     # 关系模式定义（新型关系/传统伙伴/利益关系/未界定）
  - "Discourse_Type"                    # 语段类型（经验性断言/规范性断言/展演性语段）