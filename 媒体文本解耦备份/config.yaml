# ==============================================================================
# 媒体文本解耦配置文件 - 7种子-媒体文本专用
# ==============================================================================

# ==============================================================================
# 📁 文件路径配置
# ==============================================================================
file_paths:
  # 输入文件夹路径：包含待处理的Excel文件
  # 支持批量处理文件夹中的所有.xlsx文件
  input: "C:\\Users\\87010\\Desktop\\媒体文本议题单元划分素材"
  
  # 输出文件夹路径：分析结果保存位置
  # 将生成analyzed_*.xlsx文件、宏观块数据库和信度检验文件
  output: "C:\\Users\\87010\\Desktop\\媒体文本议题单元划分结果"

# ==============================================================================
# 🔬 信度检验配置
# ==============================================================================
reliability_test:

  enabled: true  # 是否启用信度检验模式。true=生成验证样本文件（反向/正向/合并单表），false=跳过
  
  # 信度检验抽样配置（每个信源的样本上限）
  # precision: 正向检验的样本数（从AI认为相关的单元中抽取）
  # recall: 反向检验的样本数（从AI排除的宏观块中抽取）
  sampling_config:
    俄总统:
      precision: 30  # 俄总统精确率样本：建议30-50个
      recall: 10     # 俄总统召回率样本：建议10-20个
    俄语媒体:
      precision: 50  # 俄语媒体精确率样本：建议50-100个
      recall: 25     # 俄语媒体召回率样本：建议25-50个
    中文媒体:
      precision: 50  # 中文媒体精确率样本：建议50-100个
      recall: 25     # 中文媒体召回率样本：建议25-50个
    英语媒体:
      precision: 50  # 英语媒体精确率样本：建议50-100个
      recall: 25     # 英语媒体召回率样本：建议25-50个
    未知来源:
      precision: 50  # 未知来源精确率样本：建议50-100个
      recall: 25     # 未知来源召回率样本：建议25-50个

# ==============================================================================
# 🔄 API重试策略配置（简化版本）
# ==============================================================================
api_retry_config:
  attempts_per_model: 3        # 每个模型连续尝试3次
  max_model_switches: 2        # 最多切换5次：主模型3次→备用模型3次→主模型3次→备用模型3次→主模型3次→备用模型3次→放弃(共18次尝试)
                               # 注意：如果没有备用模型或备用模型与主模型相同，则只尝试3次就放弃
  retry_delays: [2, 5, 10]         # 重试延迟（秒）
  max_concurrent_requests: 2    # 最大并发请求数
  queue_timeout: 30.0          # 队列等待超时（秒）

# ==============================================================================
# 💾 缓冲区配置
# ==============================================================================
buffer_config:
  # 分析结果缓冲区大小（条数）
  analysis_buffer_limit: 20
  # 宏观块缓冲区大小（条数）
  macro_chunk_buffer_limit: 40

# ==============================================================================
# 🤖 API请求参数配置
# ==============================================================================
api_request_params:
  # 温度参数：控制输出的随机性，0=确定性输出
  temperature: 0
  # 响应格式：强制JSON格式输出
  response_format:
    type: "json_object"

# ==============================================================================
# 📊 语言处理配置
# ==============================================================================
# 不同语言的文本长度限制和超时配置
LANGUAGE_CONFIGS:
  zh:  # 中文配置
    # 单个文本最大token数：超过此长度跳过处理
    MAX_SINGLE_TEXT: 30000
    # 每批最大宏观块数：控制内存使用
    MAX_MACRO_CHUNKS_PER_BATCH: 100
  en:  # 英语配置
    # 单个文本最大token数：英文可处理更长文本
    MAX_SINGLE_TEXT: 30000
    # 每批最大宏观块数：与中文保持一致
    MAX_MACRO_CHUNKS_PER_BATCH: 100
  ru:  # 俄语配置
    # 单个文本最大token数：俄文介于中英文之间
    MAX_SINGLE_TEXT: 30000
    # 每批最大宏观块数：与中英文保持一致
    MAX_MACRO_CHUNKS_PER_BATCH: 100

# ==============================================================================
# ⏱️ 统一超时配置
# ==============================================================================
# 基于token数的统一超时配置（所有语言通用）
# 因为相同token数的文本，无论什么语言，AI处理负荷都是一样的
TIMEOUT_CONFIG:
  # Token数阈值配置：用于分级超时
  TOKEN_THRESHOLD_SHORT: 2000   # 短文本阈值
  TOKEN_THRESHOLD_MEDIUM: 4000  # 中等文本阈值
  # API超时时间配置（秒）：基于token数的分级超时
  TIMEOUT_SHORT: 400    # 短文本超时时间
  TIMEOUT_MEDIUM: 500   # 中等文本超时时间
  TIMEOUT_LONG: 500     # 长文本超时时间

# ==============================================================================
# 💾 数据处理配置
# ==============================================================================
data_processing:
  # 失败处理策略：true=跳过失败继续，false=遇到失败立即停止
  skip_failed_texts: true
  
  # 批处理配置：启用批量处理宏观块以提高效率
  enable_batch_processing: true  # true=启用批处理，false=单个处理（推荐先测试）
  batch_size: 20                   # 每批处理的宏观块数量（建议3-10个）
  
  # 长文本阈值配置：宏观块长度超过此值时自动切换到长文本模型（单位：token数，所有语言通用）
  LONG_TEXT_THRESHOLD: 1200  # 长文本token数阈值（所有语言通用）
  
  # 极短文本阈值配置：宏观块长度小于此值时使用快速模型（单位：token数）
  SHORT_TEXT_THRESHOLD: 100  # 极短文本token数阈值（所有语言通用）
  
  # 数据质量验证阈值
  quality_thresholds:
    min_macro_chunk_chars: 20      # 宏观块最小字符数（用于数据异常检测）
    min_macro_chunk_chars_strict: 80  # 宏观块最小字符数（严格模式）
    text_similarity_threshold: 0.7     # 文本相似度匹配阈值
    token_char_ratio: 2                # Token与字符数的粗略比例（1 token ≈ N 字符）

# ==============================================================================
# 🔄 一致性保证配置
# ==============================================================================
# 为确保重新分析时结果一致性，系统会：
# 1. 保存第一次分析时的宏观块信息到宏观块数据库
# 2. 重新分析时优先使用已保存的宏观块，而不是重新生成
# 3. 即使API调用失败，也会保存基本的宏观块信息用于重新分析
# 4. 这样可以确保多次运行的结果完全一致

# ==============================================================================
# 🎲 随机化配置
# ==============================================================================
randomization:
  # 随机种子：用于确保结果可重现
  random_seed: 2025

# ==============================================================================
# 🔑 API配置
# ==============================================================================
api_config:
  # API密钥列表：支持多个密钥轮换
  API_KEYS:
    - "sk-oS1mPWSBCvf5czQQ1CyRXRGWOWQ4CFWis8qNV0UlEqbQYzoH"
  
  # API基础URL：代理服务地址
  BASE_URL: "https://openai.sharkmagic.com.cn/v1"

# ==============================================================================
# 🤖 模型池配置
# ==============================================================================
model_pools:
  # 主模型配置：优先使用的高性能模型
  primary_models:
    MACRO_CHUNKING: "[官自-0.7]gemini-2-5-flash"           # 宏观分块：快速轻量，适合结构化任务
    INTEGRATED_ANALYSIS: "[官自-0.7]gemini-2-5-flash"       # 一体化分析：高精度，适合复杂分析
    INTEGRATED_ANALYSIS_LONG: "[官自-3]gemini-2-5-pro"      # 长文本分析：专门处理超长宏观块
    INTEGRATED_ANALYSIS_SHORT: "[官自-0.3]gemini-2-5-flash-lite"  # 极短文本：专门处理极短宏观块
  
  # 备用模型池：主模型失败时的降级选择（按优先级排序）
  fallback_models:
    MACRO_CHUNKING:
      - "[防过载-1]gemini-flash"                            # 宏观分块备用：防过载版本
    INTEGRATED_ANALYSIS:
      - "[防过载-1]gemini-flash"                            # 一体化分析备用：防过载版本
    INTEGRATED_ANALYSIS_LONG:
      - ""                              # 长文本分析备用：防过载版本
    INTEGRATED_ANALYSIS_SHORT:
      - "[官自-0.7]gemini-2-5-flash"                     # 极短文本备用：防过载版本

# ==============================================================================
# 📋 Excel列名映射
# ==============================================================================
# 将Excel文件中的列名映射为程序内部使用的标准名称
column_mapping:
  ID: "序号"           # 文章ID列名：Excel中用于标识每篇文章的唯一编号
  MEDIA_TITLE: "标题"  # 文章标题列名：Excel中存储文章标题的列名
  MEDIA_TEXT: "text"   # 文章正文列名：Excel中存储文章正文内容的列名

# ==============================================================================
# 📊 统一输出列
# ==============================================================================
# 用于强制补齐，避免不同语言/批次导致列缺失
# 该列表定义了所有输出Excel文件必须包含的列名
required_output_columns:
  # 输入基础列（保持在最前）
  - "序号"      # 文章唯一标识
  - "日期"      # 文章发布日期
  - "标题"      # 文章标题
  - "token数"   # 文章token数统计
  - "text"      # 文章正文内容
  
  # 议题单元输出列
  - "Unit_ID"                    # 议题单元唯一标识
  - "Source"                     # 信源标识（俄总统/俄语媒体/中文媒体/英语媒体/未知来源）
  - "Macro_Chunk_ID"             # 宏观块唯一标识
  - "speaker"                    # 发言人/信源标准化标识
  - "Unit_Text"                  # 议题单元原文
  - "seed_sentence"              # 种子句子（用于单元构建的锚点）
  - "expansion_logic"            # 单元构建逻辑报告
  - "Unit_Hash"                  # 单元文本哈希值（用于去重）
  - "processing_status"          # 处理状态（SUCCESS/NO_RELEVANT/API_FAILED）
  
  # 核心事件提取
  - "Incident"                   # 核心事件、观点或行动的一句话概括
  
  # 六维框架功能分析（对象格式）
  - "Frame_ProblemDefinition"        # 问题建构（对象列表：quote, reason, reasoning_pattern）
  - "Frame_ResponsibilityAttribution" # 归因指责（对象列表：quote, reason, reasoning_pattern）
  - "Frame_MoralEvaluation"          # 道德评价（对象列表：quote, reason, reasoning_pattern）
  - "Frame_SolutionRecommendation"   # 方案建议（对象列表：quote, reason, reasoning_pattern）
  - "Frame_ActionStatement"          # 事实宣称（对象列表：quote, reason, reasoning_pattern）
  - "Frame_CausalExplanation"        # 因果解释（对象列表：quote, reason, reasoning_pattern）
  
  # 核心分析维度
  - "Valence"                           # 情感极性（正面/负面/中立/事实陈述）
  - "Evidence_Type"                     # 证据类型（数据/统计/官方声明/专家观点等）
  - "Attribution_Level"                 # 归因层级（个体/国家/社会/系统/不适用）
  - "Temporal_Focus"                    # 时间焦点（追溯/现状/展望/混合）
  - "Primary_Actor_Type"                # 主要行动者类型（国家/个人/次国家/国际组织等）
  - "Geographic_Scope"                  # 地理范围（双边/区域/全球/国内/混合）
  - "Relationship_Model_Definition"     # 关系模式定义（新型关系/传统伙伴/利益关系/未界定）
  - "Discourse_Type"                    # 语段类型（经验性断言/规范性断言/展演性语段）
